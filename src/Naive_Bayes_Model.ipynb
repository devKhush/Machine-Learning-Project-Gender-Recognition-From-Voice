{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB, MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../assests/scaled_voice_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>modindx</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.017139</td>\n",
       "      <td>2.012536</td>\n",
       "      <td>0.155201</td>\n",
       "      <td>-1.784546</td>\n",
       "      <td>0.116305</td>\n",
       "      <td>-0.230102</td>\n",
       "      <td>1.407711</td>\n",
       "      <td>1.638474</td>\n",
       "      <td>0.699608</td>\n",
       "      <td>1.235429</td>\n",
       "      <td>0.317097</td>\n",
       "      <td>0.185051</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.242956</td>\n",
       "      <td>1.167716</td>\n",
       "      <td>0.209318</td>\n",
       "      <td>-0.236093</td>\n",
       "      <td>0.295384</td>\n",
       "      <td>-0.244366</td>\n",
       "      <td>1.617131</td>\n",
       "      <td>1.963082</td>\n",
       "      <td>0.471396</td>\n",
       "      <td>0.061898</td>\n",
       "      <td>-1.072361</td>\n",
       "      <td>0.505507</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594624</td>\n",
       "      <td>-0.628856</td>\n",
       "      <td>0.383436</td>\n",
       "      <td>0.459674</td>\n",
       "      <td>0.778532</td>\n",
       "      <td>-0.223221</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>-1.721108</td>\n",
       "      <td>-0.005193</td>\n",
       "      <td>0.131058</td>\n",
       "      <td>0.996114</td>\n",
       "      <td>-0.042381</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410492</td>\n",
       "      <td>-1.411220</td>\n",
       "      <td>0.306990</td>\n",
       "      <td>0.786895</td>\n",
       "      <td>-0.472162</td>\n",
       "      <td>-0.225505</td>\n",
       "      <td>-1.279564</td>\n",
       "      <td>-1.029810</td>\n",
       "      <td>0.466451</td>\n",
       "      <td>1.474043</td>\n",
       "      <td>3.100587</td>\n",
       "      <td>0.767026</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.804964</td>\n",
       "      <td>-1.414826</td>\n",
       "      <td>0.709370</td>\n",
       "      <td>0.811088</td>\n",
       "      <td>0.051118</td>\n",
       "      <td>-0.234219</td>\n",
       "      <td>-0.741627</td>\n",
       "      <td>-1.293786</td>\n",
       "      <td>0.707130</td>\n",
       "      <td>0.488538</td>\n",
       "      <td>0.692233</td>\n",
       "      <td>-0.538644</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75      kurt    sp.ent  \\\n",
       "0 -1.017139  2.012536  0.155201 -1.784546  0.116305 -0.230102  1.407711   \n",
       "1 -0.242956  1.167716  0.209318 -0.236093  0.295384 -0.244366  1.617131   \n",
       "2  0.594624 -0.628856  0.383436  0.459674  0.778532 -0.223221  0.329348   \n",
       "3  0.410492 -1.411220  0.306990  0.786895 -0.472162 -0.225505 -1.279564   \n",
       "4  0.804964 -1.414826  0.709370  0.811088  0.051118 -0.234219 -0.741627   \n",
       "\n",
       "        sfm      mode   meanfun    minfun   modindx  gender  \n",
       "0  1.638474  0.699608  1.235429  0.317097  0.185051  female  \n",
       "1  1.963082  0.471396  0.061898 -1.072361  0.505507  female  \n",
       "2 -1.721108 -0.005193  0.131058  0.996114 -0.042381    male  \n",
       "3 -1.029810  0.466451  1.474043  3.100587  0.767026  female  \n",
       "4 -1.293786  0.707130  0.488538  0.692233 -0.538644  female  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavieBayesModel:\n",
    "\n",
    "    def Gaussian_Naive_Bayes(x_train, y_train, x_test, y_test, i, k, display_stats=False):\n",
    "        NB_model = GaussianNB()\n",
    "        NB_model.fit(x_train,y_train)\n",
    "        y_pred = NB_model.predict(x_test)\n",
    "\n",
    "        # Accuracy, Precision, Recall, F1-score of Model\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        if display_stats:\n",
    "            print(f\"Statistics for Fold {i} in K-fold (k={k}) 'Logistic Regression' algorithm\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1-score: {f1_score}\")\n",
    "            print()\n",
    "            \n",
    "        return np.array([accuracy, precision, recall, f1_score])\n",
    "\n",
    "    def Multinomial_Naive_Bayes(x_train, y_train, x_test, y_test, i, k, display_stats=False):\n",
    "        NB_model = MultinomialNB()\n",
    "        NB_model.fit(x_train,y_train)\n",
    "        y_pred = NB_model.predict(x_test)\n",
    "\n",
    "        # Accuracy, Precision, Recall, F1-score of Model\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        if display_stats:\n",
    "            print(f\"Statistics for Fold {i} in K-fold (k={k}) 'Logistic Regression' algorithm\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1-score: {f1_score}\")\n",
    "            print()\n",
    "            \n",
    "        return np.array([accuracy, precision, recall, f1_score])\n",
    "\n",
    "    def Categorical_Naive_Bayes(x_train, y_train, x_test, y_test, i, k, display_stats=False):\n",
    "        NB_model = CategoricalNB()\n",
    "        NB_model.fit(x_train,y_train)\n",
    "        y_pred = NB_model.predict(x_test)\n",
    "\n",
    "        # Accuracy, Precision, Recall, F1-score of Model\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        if display_stats:\n",
    "            print(f\"Statistics for Fold {i} in K-fold (k={k}) 'Logistic Regression' algorithm\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1-score: {f1_score}\")\n",
    "            print()\n",
    "            \n",
    "        return np.array([accuracy, precision, recall, f1_score])\n",
    "\n",
    "    def Bernoulli_Naive_Bayes(x_train, y_train, x_test, y_test, i, k, display_stats=False):\n",
    "        NB_model = BernoulliNB()\n",
    "        NB_model.fit(x_train,y_train)\n",
    "        y_pred = NB_model.predict(x_test)\n",
    "\n",
    "        # Accuracy, Precision, Recall, F1-score of Model\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "        f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        if display_stats:\n",
    "            print(f\"Statistics for Fold {i} in K-fold (k={k}) 'Logistic Regression' algorithm\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1-score: {f1_score}\")\n",
    "            print()\n",
    "            \n",
    "        return np.array([accuracy, precision, recall, f1_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.899944096154614\n",
      "Mean Precision: 0.901324193932329\n",
      "Mean Recall: 0.899944096154614\n",
      "Mean F1-score: 0.8998483155418237\n"
     ]
    }
   ],
   "source": [
    "def run_Gaussian_NaiveBayes():\n",
    "    x = df.drop('gender', axis=1)\n",
    "    y = df['gender']\n",
    "\n",
    "    k = 10\n",
    "    i = 0\n",
    "    k_fold = KFold(n_splits=k)\n",
    "\n",
    "    # Holds Mean of {accuracy, precision, recall, f1_score}\n",
    "    mean_stats = np.zeros(4)\n",
    "\n",
    "    for train_index, test_index in k_fold.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        stats = NavieBayesModel.Gaussian_Naive_Bayes(x_train, y_train, x_test, y_test, i:=i+1, k, display_stats=False)\n",
    "        # print(stats)\n",
    "        mean_stats = mean_stats + stats\n",
    "        \n",
    "    # Take mean of {accuracy, precision, recall, f1_score}\n",
    "    mean_stats = mean_stats / k\n",
    "\n",
    "    print(f\"Mean accuracy: {mean_stats[0]}\")\n",
    "    print(f\"Mean Precision: {mean_stats[1]}\")\n",
    "    print(f\"Mean Recall: {mean_stats[2]}\")\n",
    "    print(f\"Mean F1-score: {mean_stats[3]}\")\n",
    "\n",
    "run_Gaussian_NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Bernoulli Naive Byes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.8617497903605799\n",
      "Mean Precision: 0.8639765398839593\n",
      "Mean Recall: 0.8617497903605799\n",
      "Mean F1-score: 0.8614960379476353\n"
     ]
    }
   ],
   "source": [
    "def run_Bernoulli_NaiveBayes():\n",
    "    x = df.drop('gender', axis=1)\n",
    "    y = df['gender']\n",
    "\n",
    "    k = 10\n",
    "    i = 0\n",
    "    k_fold = KFold(n_splits=k)\n",
    "\n",
    "    # Holds Mean of {accuracy, precision, recall, f1_score}\n",
    "    mean_stats = np.zeros(4)\n",
    "\n",
    "    for train_index, test_index in k_fold.split(x):\n",
    "        x_train, x_test = x.loc[train_index], x.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        stats = NavieBayesModel.Bernoulli_Naive_Bayes(x_train, y_train, x_test, y_test, i:=i+1, k, display_stats=False)\n",
    "        # print(stats)\n",
    "        mean_stats = mean_stats + stats\n",
    "        \n",
    "    # Take mean of {accuracy, precision, recall, f1_score}\n",
    "    mean_stats = mean_stats / k\n",
    "\n",
    "    print(f\"Mean accuracy: {mean_stats[0]}\")\n",
    "    print(f\"Mean Precision: {mean_stats[1]}\")\n",
    "    print(f\"Mean Recall: {mean_stats[2]}\")\n",
    "    print(f\"Mean F1-score: {mean_stats[3]}\")\n",
    "\n",
    "run_Bernoulli_NaiveBayes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f91e35da70fd7a53ceee9ab287ed040d81eb2ccfac088551011048c25bbd6e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
